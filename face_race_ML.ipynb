{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQyZp6uGppoJJiptDrkaRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audachang/ML_collections/blob/main/face_race_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU1aP9QFXEoN",
        "outputId": "d1584002-702c-4432-c78e-dc61554689a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ML collection using pytorch to predict category of custom dataset](https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/Basics/custom_dataset)"
      ],
      "metadata": {
        "id": "OfE5_q6FQzvS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lto8hc3LgLta"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
        "import torchvision\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        ")  # Gives easier dataset managment and creates mini batches\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "dpath = './gdrive/MyDrive/mycolab/data/'\n",
        "imgdir = os.path.join(dpath, '346faces_sameBG_grey_adjBright')\n",
        "annote_file = './gdrive/MyDrive/mycolab/data/346faces_allData.csv'  # or whatever the path to the downloaded data is"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking on column names"
      ],
      "metadata": {
        "id": "kmFBQrHXB-rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = pd.read_csv(annote_file)\n",
        "tmp.iloc[0,]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAqFTrnXz1BA",
        "outputId": "c44e37f5-7a96-455f-cb13-bb8fc57ca2d7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "face                                             AUF_1\n",
              "face_race                                           AU\n",
              "face_gender                                          F\n",
              "image_grey_adj             AUF_1_squared_adjBright.png\n",
              "Sr_column_grey_adj                            0.480841\n",
              "manual_oAI_raw                                1.881759\n",
              "FaceMesh_oAI_raw                              0.763622\n",
              "FaceMesh_oAI_normalized                       0.845129\n",
              "prototypicality.N.54.                         4.203704\n",
              "sensitivity.N.56.                             0.360025\n",
              "criterion.N.56.                                    0.0\n",
              "gray_att_upr                                  4.948718\n",
              "gray_sym_upr                                  6.055556\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading structured data"
      ],
      "metadata": {
        "id": "WnuZ9zojZI6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class faceDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, tarlab, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "\n",
        "        self.annotations['label'] = \\\n",
        "          self.annotations[tarlab].rank(method='dense', ascending=False).astype(int)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 3])\n",
        "        image = Image.open(img_path)\n",
        "        y_label = torch.tensor(int(self.annotations.loc[index, 'label']))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)"
      ],
      "metadata": {
        "id": "WO9ImEfttdci"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up training parameters"
      ],
      "metadata": {
        "id": "N2gj2dmgCDyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "in_channel = 3\n",
        "num_classes = 2\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "TfkLEMI4wef-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset"
      ],
      "metadata": {
        "id": "WiejKJzCCVMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = faceDataset(\n",
        "    csv_file=annote_file,\n",
        "    root_dir=imgdir,\n",
        "    tarlab = 'face_race',\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "sOcOPSDKttT0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting test and training set"
      ],
      "metadata": {
        "id": "bjYHUqrhCYpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 跟 test 的大小\n",
        "test_size = int(len(dataset)*0.2)\n",
        "train_size = len(dataset)- int(len(dataset)*0.2)\n",
        "\n",
        "# 切割資料集\n",
        "train_dataset, test_dataset = \\\n",
        "  torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# 套上dataloader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "el7xXVYNt-XJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initiate model"
      ],
      "metadata": {
        "id": "LaSsx0uPCc1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.googlenet(pretrained=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnDolSzAuTMA",
        "outputId": "f56d286f-45b0-4476-b845-68a0e75bb1f1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "7TAkOwecvAVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFDZJ4Wyu_6g",
        "outputId": "de5fcf41-e419-4e78-d456-89944f1242c6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost at epoch 0 is 3.816496253013611\n",
            "Cost at epoch 1 is 0.280390696393119\n",
            "Cost at epoch 2 is 0.08371078248860107\n",
            "Cost at epoch 3 is 0.07526595621473259\n",
            "Cost at epoch 4 is 0.031192468893196847\n",
            "Cost at epoch 5 is 0.00910488883447316\n",
            "Cost at epoch 6 is 0.02285941954081257\n",
            "Cost at epoch 7 is 0.0024293706260828506\n",
            "Cost at epoch 8 is 0.0037911036569211218\n",
            "Cost at epoch 9 is 0.007117271513885094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check accuracy on training to see how good our model is\n"
      ],
      "metadata": {
        "id": "aGD7HgZn4bwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
        "        )\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "print(\"Checking accuracy on Training Set\")\n",
        "check_accuracy(train_loader, model)\n",
        "\n",
        "print(\"Checking accuracy on Test Set\")\n",
        "check_accuracy(test_loader, model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubidfDnl4XXm",
        "outputId": "a475209e-4b12-44d6-c5eb-51fad329db54"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on Training Set\n",
            "Got 277 / 277 with accuracy 100.00\n",
            "Checking accuracy on Test Set\n",
            "Got 68 / 69 with accuracy 98.55\n"
          ]
        }
      ]
    }
  ]
}